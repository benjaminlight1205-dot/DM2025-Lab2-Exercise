{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Student Information**\n",
    "Name:\n",
    "閔珩晅\n",
    "Student ID:113072519\n",
    "GitHub ID:benjaminlight1205-dot\n",
    "\n",
    "Kaggle name:Benjamin Min 123\n",
    "\n",
    "Kaggle private scoreboard snapshot: 0.6102\n",
    "\n",
    "![pic_ranking.png](./pics/pic_ranking.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Instructions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab we have divided the assignments into **three phases/parts**. The `first two phases` refer to the `exercises inside the Master notebooks` of the [DM2025-Lab2-Exercise Repo](https://github.com/difersalest/DM2025-Lab2-Exercise.git). The `third phase` refers to an `internal Kaggle competition` that we are gonna run among all the Data Mining students. Together they add up to `100 points` of your grade. There are also some `bonus points` to be gained if you complete `extra exercises` in the lab **(bonus 15 pts)** and in the `Kaggle Competition report` **(bonus 5 pts)**.\n",
    "\n",
    "**Environment recommendations to solve lab 2:**\n",
    "- **Phase 1 exercises:** Need GPU for training the models explained in that part, if you don't have a GPU in your laptop it is recommended to run in Colab or Kaggle for a faster experience, although with CPU they can still be solved but with a slower execution.\n",
    "- **Phase 2 exercises:** We use Gemini's API so everything can be run with only CPU without a problem.\n",
    "- **Phase 3 exercises:** For the competition you will probably need GPU to train your models, so it is recommended to use Colab or Kaggle if you don't have a laptop with a dedicated GPU.\n",
    "- **Optional Ollama Notebook (not graded):** You need GPU, at least 4GB of VRAM with 16 GB of RAM to run the local open-source LLM models. \n",
    "\n",
    "## **Phase 1 (30 pts):**\n",
    "\n",
    "1. __Main Exercises (25 pts):__ Do the **take home exercises** from Sections: `1. Data Preparation` to `9. High-dimension Visualization: t-SNE and UMAP`, in the [DM2025-Lab2-Master-Phase_1 Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_1.ipynb). Total: `8 exercises`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 3th, 11:59 pm, Monday)`**\n",
    "\n",
    "2. **Code Comments (5 pts):** **Tidy up the code in your notebook**. \n",
    "\n",
    "## **Phase 2 (30 pts):**\n",
    "\n",
    "1. **Main Exercises (25 pts):** Do the remaining **take home exercises** from Section: `2. Large Language Models (LLMs)` in the [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb). Total: `5 exercises required from sections 2.1, 2.2, 2.4 and 2.6`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**\n",
    "\n",
    "2. **Code Comments (5 pts):** **Tidy up the code in your notebook**. \n",
    "\n",
    "3. **`Bonus (15 pts):`** Complete the bonus exercises in the [DM2025-Lab2-Master-Phase_2_Bonus Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Bonus.ipynb) and [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb) `where 2 exercises are counted as bonus from sections 2.3 and 2.5 in the main notebook`. Total: `7 exercises`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**\n",
    "\n",
    "## **Phase 3 (40 pts):**\n",
    "\n",
    "1. **Kaggle Competition Participation (30 pts):** Participate in the in-class **Kaggle Competition** regarding Emotion Recognition on Twitter by clicking in this link: **[Data Mining Class Kaggle Competition](https://www.kaggle.com/t/3a2df4c6d6b4417e8bf718ed648d7554)**. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20 pts of the 30 pts in this competition participation part.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (0.6N + 1 - x) / (0.6N) * 10 + 20 points, where N is the total number of participants, and x is your rank. (ie. If there are 100 participants and you rank 3rd your score will be (0.6 * 100 + 1 - 3) / (0.6 * 100) * 10 + 20 = 29.67% out of 30%.)   \n",
    "    Submit your last submission **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**. Make sure to take a screenshot of your position at the end of the competition and store it as `pic_ranking.png` under the `pics` folder of this repository and rerun the cell **Student Information**.\n",
    "\n",
    "2. **Competition Report (10 pts)** A report section to be filled in inside this notebook in Markdown Format, we already provided you with the template below. You need to describe your work developing the model for the competition. The report should include a section describing briefly the following elements: \n",
    "* Your preprocessing steps.\n",
    "* The feature engineering steps.\n",
    "* Explanation of your model.\n",
    "\n",
    "* **`Bonus (5 pts):`**\n",
    "    * You will have to describe more detail in the previous steps.\n",
    "    * Mention different things you tried.\n",
    "    * Mention insights you gained. \n",
    "\n",
    "[Markdown Guide - Basic Syntax](https://www.markdownguide.org/basic-syntax/)\n",
    "\n",
    "**`Things to note for Phase 3:`**\n",
    "\n",
    "* **The code used for the competition should be in this Jupyter Notebook File** `DM2025-Lab2-Homework.ipynb`.\n",
    "\n",
    "* **Push the code used for the competition to your repository**.\n",
    "\n",
    "* **The code should have a clear separation for the same sections of the report, preprocessing, feature engineering and model explanation. Briefly comment your code for easier understanding, we provide a template at the end of this notebook.**\n",
    "\n",
    "* Showing the kaggle screenshot of the ranking plus the code in this notebook will ensure the validity of your participation and the report to obtain the corresponding points.\n",
    "\n",
    "After the competition ends you will have two days more to submit the `DM2025-Lab2-Homework.ipynb` with your report in markdown format and your code. Do everything **`BEFORE the deadline (Nov. 26th, 11:59 pm, Wednesday) to obtain 100% of the available points.`**\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding NTU Cool assignment.\n",
    "\n",
    "## **Deadlines:**\n",
    "\n",
    "![lab2_deadlines](./pics/lab2_deadlines.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Next you will find the template report with some simple markdown syntax explanations, use it to structure your content.\n",
    "\n",
    "You can delete the syntax suggestions after you use them.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# **Project Report**\n",
    "\n",
    "**Syntax:** `#` creates the largest heading (H1).\n",
    "\n",
    "---\n",
    "**Syntax:** `---` creates a horizontal rule (a separator line).\n",
    "\n",
    "## 1. Model Development (10 pts Required)\n",
    "\n",
    "**Syntax:** `##` creates a secondary heading (H2).\n",
    "\n",
    "**Describe briefly each section, you can add graphs/charts to support your explanations.**\n",
    "\n",
    "### 1.1 Preprocessing Steps\n",
    "\n",
    "**Syntax:** `###` creates a tertiary heading (H3).\n",
    "\n",
    "[Content for Preprocessing]\n",
    "\n",
    "**Example Syntax for Content:**\n",
    "*   **Bold text:** `**text**`\n",
    "*   *Italic text*: `*text*`\n",
    "*   Bullet point list:\n",
    "    * Item 1\n",
    "    * Item 2\n",
    "\n",
    "Markdown Syntax to Add Image: `![Description of the Image](./your_local_folder/name_of_the_image.png)`\n",
    "\n",
    "![Example Markdown Syntax to Add Image](./pics/example_md_img.png)\n",
    "\n",
    "### 1.2 Feature Engineering Steps\n",
    "\n",
    "[Content for Feature Engineering]\n",
    "\n",
    "### 1.3 Explanation of Your Model\n",
    "\n",
    "[Content for Model Explanation]\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Bonus Section (5 pts Optional)\n",
    "\n",
    "**Add more detail in previous sections**\n",
    "\n",
    "### 2.1 Mention Different Things You Tried\n",
    "\n",
    "[Content for Experiments]\n",
    "\n",
    "### 2.2 Mention Insights You Gained\n",
    "\n",
    "[Content for Insights]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`From here on starts the code section for the competition.`**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Competition Code**\n",
    "\n",
    "## 1. Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add the code related to the preprocessing steps in cells inside this section\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "data_id = pd.read_csv(r\"C:\\Users\\User\\Downloads\\dm-lab-2-private-competition\\data_identification.csv\")\n",
    "emotion = pd.read_csv(r\"C:\\Users\\User\\Downloads\\dm-lab-2-private-competition\\emotion.csv\")\n",
    "sample = pd.read_csv(r\"C:\\Users\\User\\Downloads\\dm-lab-2-private-competition\\samplesubmission.csv\")\n",
    "\n",
    "\n",
    "with open(r\"C:\\Users\\User\\Downloads\\dm-lab-2-private-competition\\final_posts.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw = json.load(f)\n",
    "\n",
    "\n",
    "posts_list = []\n",
    "for item in raw:\n",
    "    post = item[\"root\"][\"_source\"][\"post\"]\n",
    "    posts_list.append({\n",
    "        \"id\": post[\"post_id\"],\n",
    "        \"text\": post[\"text\"]\n",
    "    })\n",
    "posts_df = pd.DataFrame(posts_list)\n",
    "\n",
    "\n",
    "df = data_id.merge(posts_df, on=\"id\", how=\"left\")\n",
    "df = df.merge(emotion, on=\"id\", how=\"left\")\n",
    "\n",
    "\n",
    "train_df = df[df[\"split\"] == \"train\"].reset_index(drop=True)\n",
    "test_df  = df[df[\"split\"] == \"test\"].reset_index(drop=True)\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)      \n",
    "    text = re.sub(r\"@\\w+\", \"\", text)              \n",
    "    text = re.sub(r\"#\", \"\", text)              \n",
    "    text = re.sub(r\"[^\\w\\s\\U0001F600-\\U0001F64F]\", \" \", text)  \n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()       \n",
    "\n",
    "    return text\n",
    "\n",
    "train_df[\"clean_text\"] = train_df[\"text\"].apply(clean_text)\n",
    "test_df[\"clean_text\"] = test_df[\"text\"].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "如上，我這一段做的，是資料的預處理。\n",
    "首先，先讀入CSV 與JSON的原始資料，然後將JSON 內的結構展開成id + text的形式。\n",
    "接著，合併資料成一個大dataframe，再拆分成訓練集/ 測試集\n",
    "最後做了清洗文字內容的部分，主要是移除一些噪音，還往網址，統一格式，並且保留了emoji(emoji符號很大程度能代表這句話的情緒，應該是個重要的資訊)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add the code related to the feature engineering steps in cells inside this section\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "\n",
    "tfidf_word = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    ngram_range=(1,3),\n",
    "    min_df=2,\n",
    "    max_features=150000,\n",
    "    sublinear_tf=True,\n",
    ")\n",
    "\n",
    "\n",
    "tfidf_char = TfidfVectorizer(\n",
    "    analyzer='char',\n",
    "    ngram_range=(3,5),\n",
    "    min_df=2,\n",
    "    max_features=150000,\n",
    "    sublinear_tf=True,\n",
    ")\n",
    "\n",
    "\n",
    "combined_tfidf = FeatureUnion([\n",
    "    (\"word\", tfidf_word),\n",
    "    (\"char\", tfidf_char)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "這裡的特徵工程，我主要使用TF-IDF的做法，我分別用了詞級TF-IDF以及字元級的TF-IDF。\n",
    "詞級TF-IDF可以抓單字片語的語意，而字元級的可以處理錯字、縮寫、情緒文字。\n",
    "最後將這兩個層次的特徵工程合併起來"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Implementation Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add the code related to the model implementation steps in cells inside this section\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "model_mix = Pipeline([\n",
    "    (\"vect\", combined_tfidf),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        C=2.0,\n",
    "        max_iter=2000,\n",
    "        class_weight='balanced',\n",
    "        solver=\"liblinear\"\n",
    "    ))\n",
    "])\n",
    "\n",
    "model_mix.fit(train_df[\"clean_text\"], train_df[\"emotion\"])\n",
    "\n",
    "\n",
    "pred_train = model_mix.predict(train_df[\"clean_text\"])\n",
    "print(\"Train Macro-F1:\", f1_score(train_df[\"emotion\"], pred_train, average='macro'))\n",
    "\n",
    "\n",
    "test_df[\"emotion\"] = model_mix.predict(test_df[\"clean_text\"])\n",
    "\n",
    "\n",
    "submission_mix = sample[[\"id\"]].merge(\n",
    "    test_df[[\"id\", \"emotion\"]],\n",
    "    on=\"id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "submission_mix.to_csv(r\"C:\\Users\\User\\Downloads\\dm-lab-2-private-competition\\submission_mix.csv\", index=False)\n",
    "print(\"submission_mix.csv 已成功產生！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "這邊使用的模型，是Logistic Regression，模型設定中還包含了class_weight，以防止偏差。\n",
    "接著就是訓練訓練集，輸出結果，還後再推理預測集，最後產出需要用來提交的submission預測檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "補充:\n",
    "Logistic Regression並非是我一開始就使用的模型，我最早嘗試使用了svm的方法，不過分數一直沒怎麼提上去。\n",
    "最早的特徵工程部分，我也是用tfidf，但是是最基礎的，並沒有去細分成詞集層面以及字元級的層面，所以最開始的時候分數大多在0.5到0.6之間。\n",
    "後來改成現在這樣，才超過0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "心得:\n",
    "這次的情緒分類競賽，對我來說是一個不錯的體驗。\n",
    "我本來選這堂課，最重要的就是對情緒分析這個主題很好奇。\n",
    "提交的過程中，看到每一次調整，分數至少都有上升一些，或是至少有維持原本的分數，其實還是挺開心的，最怕就是改了後分數反而下降了。\n",
    "最後看到分數超過0.6  \n",
    "我就覺得已經差不多滿足了。\n",
    "這次的比賽最讓我收穫的，就是看到每一個步驟的重要性，不管事預處理的部分，特徵工程的部分，還是模型選擇，只要改進一項，分數就會有一步步一點點地逐步變化。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dm2025lab)",
   "language": "python",
   "name": "dm2025lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
